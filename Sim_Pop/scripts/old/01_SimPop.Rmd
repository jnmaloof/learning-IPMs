---
title: "SimPop1"
author: "Julin Maloof"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if(basename(getwd()) != "scripts") setwd("scripts")
```

First attempt at simulating a population

```{r}
library(AlphaSimR)
library(tidyverse)
library(rrBLUP)
logit <- brms::logit_scaled
inv_logit <- brms::inv_logit_scaled
```

I should play with these parameters to see how they affect LD
```{r, eval=FALSE}
system.time( 
pop0 <- runMacs2(nInd = 1000, nChr = 10, segSites = 10000,  # reduced from 100,000 for troubleshooting and fast running
                  bp = 10000000, # reduced from 100,000,000 to reduce runtime, etc
                  Ne = 1000, #250 seconds with 1000, 542 seconds with 5000.  
                            # Larger Ne = more recombination, less LD
                  histNe = 10000,
                  histGen = 1000,
                 nThreads = 5) # not clear that the multithreading is working...
)


saveRDS(pop0, file = "../output/pop0.alt.RDS")
```

```{r, eval=FALSE}
pop0 <- readRDS("../output/pop0.alt.RDS")
```


```{r, eval=TRUE}
pop0 <- quickHaplo(nInd = 1000, nChr = 10, segSites = 1000) # note segSites is per chrom
```

Germination
Initial size
Establishment
Growth rate
Flowering probability
Fruit per plant

```{r}
SP <- SimParam$new(pop0)

traitMeans <- c(#germination.logit = logit(0.33),
germination.logit = logit(1),
                size = 10,
                establishment.logit = logit(0.67),
                growth = 1, # how should growth be modeled ? relative growth rate?
                flowering.logit = logit(.25),
                fruitPerPlant = 30)

SP$addTraitA(nQtlPerChr = 500,
              mean = traitMeans,
  #            var = (traitMeans*0.25)^2, #genetic CV = 0.25 (?)
               var = rep(10, length(traitMeans)),
              gamma = FALSE, # check literature 
             # shape = 1,
              name = names(traitMeans)
)

SP$setVarE(h2=rep(0.9, length(traitMeans)))

```

```{r}
pop1 <- newPop(pop0, simParam = SP)
pop1 <- setPheno(pop1, simParam = SP)
```

```{r}
pheno <- pop1@pheno %>% as_tibble()
dim(pheno)
head(pheno)
```


Convert pheno logits to probabilities and phenotypes! 
```{r}
pheno <- pheno %>%
  mutate(across(ends_with(".logit"), .fns = inv_logit, 
         .names = "{.col}.prob")) %>%
  rename_with(.fn = \(n) str_replace(n, "\\.logit\\.prob", "\\.prob")) %>%
  mutate(germinated = rbinom(n(), size=1, prob=germination.prob),
         established = ifelse(germinated, rbinom(n(), size=1, prob=establishment.prob), NA),
         flowered = ifelse(established, rbinom(n(), size = 1, prob = flowering.prob), NA),
         growth = ifelse(established, growth, NA),
         fruitPerPlant = ifelse(flowered, fruitPerPlant, NA)
  )
  
```

```{r}
pheno %>%
  pivot_longer(everything()) %>%
  ggplot(aes(x=value)) +
  geom_histogram() +
  facet_wrap(~name, scales="free")
  
```



```{r}
geno <- pullSegSiteGeno(pop1)
dim(geno)
geno[1:10, 1:10]
```

## Genomic Prediction

remove correlated SNPs.  

```{r}
cor(geno[,1:20])
```

```{r}
source("remove_correlated_snps.R")
source("test_remove_correlated_snps.R")
```

```{r}
# Remove correlated SNPs
source("remove_correlated_snps.R")

system.time({
  # Extract chromosome information from SNP names
  chr_info <- str_extract(colnames(geno), "^[^_]+")
  unique_chrs <- unique(chr_info)
  
  # Set up parallel processing
  library(parallel)
  num_cores <- min(length(unique_chrs), detectCores() - 1)
  cl <- makeCluster(num_cores)
  
  # Export required functions and data to the cluster
  clusterExport(cl, c("remove_correlated_snps", "chr_info", "geno"))
  
  # Process each chromosome in parallel
  kept_snps_list <- parLapply(cl, unique_chrs, function(chr) {
    chr_indices <- which(chr_info == chr)
    chr_geno <- geno[, chr_indices, drop = FALSE]
    kept_indices <- remove_correlated_snps(chr_geno, cor_threshold = 0.8, 
                                          window_size = 100, chunk_size = 10000, verbose = FALSE)
    return(chr_indices[kept_indices])
  })
  
  # Stop the cluster
  stopCluster(cl)
  
  # Combine results from all chromosomes
  kept_snps <- unlist(kept_snps_list)
  
  # Create filtered genotype matrix
  geno_small <- geno[, kept_snps]
})

# Check the dimensions of the filtered genotype data
dim(geno)
dim(geno_small)
```

```{r}
# Calculate minor allele frequencies (MAF)
allele_freqs <- colMeans(geno_small) / 2
minor_allele_freqs <- pmin(allele_freqs, 1 - allele_freqs)  # MAF is always <= 0.5

# Plot MAF distribution
hist(minor_allele_freqs, 
  main="Minor Allele Frequency Distribution", 
  xlab="Minor Allele Frequency", 
  breaks=20,
  xlim=c(0,0.5))

# Get some summary statistics of MAF
summary(minor_allele_freqs)

# filter for maf
geno_small_filter <- geno_small[, minor_allele_freqs >= 0.1]
dim(geno_small_filter)
```

```{r, eval=FALSE}
if(min(geno_small) == 0) geno_small <- geno_small - 1
if(min(geno_small_filter) == 0) geno_small_filter <- geno_small_filter - 1


# 260 seconds
system.time(ans <- mixed.solve(pheno$size, Z = geno_small, method = "REML"))

prediction <- (geno_small %*% ans$u ) + ans$beta[1] # add intercept

# Check the prediction
head(prediction)
# Compare with actual phenotypes
comparison <- data.frame(Actual = pheno$size, Predicted = prediction)
head(comparison)
# Calculate prediction accuracy
cor(comparison$Actual, comparison$Predicted)
# Plot actual vs predicted
ggplot(comparison, aes(x = Actual, y = Predicted)) +
  geom_point() +
  geom_smooth(method = "lm", color = "blue") +
  labs(title = "Actual vs Predicted Size",
       x = "Actual Size",
       y = "Predicted Size") +
  theme_classic()
```


Test a single test/train split
```{r, eval=TRUE}
if(min(geno_small) == 0) geno_small <- geno_small - 1
if(min(geno_small_filter) == 0) geno_small_filter <- geno_small_filter - 1
#set.seed(555)
train <- sample(1:nrow(pheno), size=0.7 * nrow(pheno))
test <- setdiff(1:nrow(pheno), train)

pheno_train <- pheno[train,]
pheno_test <- pheno[test,]

geno_train <- geno_small_filter[train,]
geno_test <- geno_small_filter[test,]

ans.train <- mixed.solve(pheno_train$size, Z = geno_train, method = "REML")

prediction.train <- geno_train %*% ans.train$u + ans.train$beta[1]

cor(prediction.train, pheno_train$size)

prediction.test <- (geno_test %*% ans.train$u) + ans.train$beta[1] 

cor(prediction.test,  pheno_test$size)
```



```{r, eval=FALSE}
# K-fold Cross Validation for Genomic Prediction
set.seed(123) # For reproducibility
k <- 5 # Number of folds
n <- nrow(pheno)
fold_indices <- sample(rep(1:k, length.out = n))

# Initialize a data frame to store results
cv_results <- data.frame(
  Fold = integer(),
  Trait = character(),
  Correlation = numeric(),
  RMSE = numeric()
)

# Function to calculate RMSE
rmse <- function(actual, predicted) {
  sqrt(mean((actual - predicted)^2, na.rm = TRUE))
}

# Run cross-validation for each trait
traits <- c("size", "growth", "fruitPerPlant")

for (trait in traits) {
  # Skip if too many NAs
  if (sum(!is.na(pheno[[trait]])) < n * 0.5) {
    cat("Skipping", trait, "due to too many NAs\n")
    next
  }
  
  cat("Running cross-validation for trait:", trait, "\n")
  
  for (i in 1:k) {
    # Split data into training and testing sets
    test_indices <- which(fold_indices == i)
    train_indices <- which(fold_indices != i)
    
    # Extract training and testing data
    X_train <- geno_small[train_indices, ]
    y_train <- pheno[[trait]][train_indices]
    X_test <- geno_small[test_indices, ]
    y_test <- pheno[[trait]][test_indices]
    
    # Skip NA values
    valid_train <- !is.na(y_train)
    if (sum(valid_train) < 10) { # Need minimum number of samples
      cat("  Fold", i, "has insufficient non-NA training data\n")
      next
    }
    
    # Train model
    model <- try(mixed.solve(y_train[valid_train], 
                             Z = X_train[valid_train, ], 
                             method = "REML"), silent = TRUE)
    
    if (class(model) == "try-error") {
      cat("  Error in fold", i, "- skipping\n")
      next
    }
    
    # Make predictions on test set
    predictions <- as.vector(X_test %*% model$u) + model$beta[1]
    
    # Evaluate predictions
    valid_test <- !is.na(y_test)
    if (sum(valid_test) < 5) { # Need minimum number for evaluation
      cat("  Fold", i, "has insufficient non-NA test data\n")
      next
    }
    
    correlation <- cor(y_test[valid_test], predictions[valid_test], 
                      use = "complete.obs")
    error <- rmse(y_test[valid_test], predictions[valid_test])
    
    # Store results
    cv_results <- rbind(cv_results, data.frame(
      Fold = i,
      Trait = trait,
      Correlation = correlation,
      RMSE = error
    ))
  }
}

# Summarize results by trait
cv_summary <- cv_results %>%
  group_by(Trait) %>%
  summarize(
    Mean_Correlation = mean(Correlation, na.rm = TRUE),
    SD_Correlation = sd(Correlation, na.rm = TRUE),
    Mean_RMSE = mean(RMSE, na.rm = TRUE),
    SD_RMSE = sd(RMSE, na.rm = TRUE),
    n_folds = n()
  )

# Print summary
print(cv_summary)

# Create visualization
ggplot(cv_results, aes(x = Trait, y = Correlation)) +
  geom_boxplot() +
  geom_jitter(width = 0.2, alpha = 0.5, color = "blue") +
  theme_classic() +
  labs(title = "Cross-Validation Results by Trait",
       y = "Prediction Accuracy (Correlation)",
       x = "Trait")

# Plot RMSE
ggplot(cv_results, aes(x = Trait, y = RMSE)) +
  geom_boxplot() +
  geom_jitter(width = 0.2, alpha = 0.5, color = "red") +
  theme_classic() +
  labs(title = "Cross-Validation Error by Trait",
       y = "RMSE",
       x = "Trait")
```


```{r}
# Random Forest Genomic Prediction using tidymodels
library(tidymodels)
library(ranger) # Fast implementation of Random Forest
library(future)
plan(multisession, workers = 7)

model_data <- tibble(cbind(size=pheno$size, as_tibble(geno_small_filter)))
  
  # Split data into training and testing
  set.seed(42)
  data_split <- initial_split(model_data, prop = 0.8)
  train_data <- training(data_split)
  test_data <- testing(data_split)
  
  # Create cross-validation folds for hyperparameter tuning
  cv_folds <- vfold_cv(train_data, v = 5)
  
  # Define model specification with hyperparameter tuning
  rf_model <- rand_forest(
    mtry = tune(),
    min_n = tune(),
    trees = 500
  ) %>%
    set_engine("ranger", importance = "impurity") %>%
    set_mode("regression")
  
  # Define recipe
  rf_recipe <- recipe(size ~ ., data = train_data)
  
  # Create workflow
  rf_workflow <- workflow() %>%
    add_model(rf_model) %>%
    add_recipe(rf_recipe)
  
  # Define grid for tuning
  rf_grid <- grid_regular(
    mtry(range = c(floor(sqrt(ncol(train_data) - 1)), floor(ncol(train_data)/3))),
    min_n(range = c(2, 10)),
    levels = 3
  )
  
  # Tune hyperparameters
  rf_tuning <- tune_grid(
    rf_workflow,
    resamples = cv_folds,
    grid = rf_grid,
    metrics = metric_set(rmse, rsq)
  )
  
rf_tuning %>% unnest(.metrics) %>% filter(.metric=="rsq") %>% arrange(desc(.estimate))

  # Select best hyperparameters
  best_params <- select_best(rf_tuning, metric = "rmse")
  
  # Finalize workflow with best parameters
  final_workflow <- rf_workflow %>%
    finalize_workflow(best_params)
  
  # Train final model
  final_fit <- fit(final_workflow, train_data)
  
  # Evaluate on test data
  test_results <- final_fit %>%
    predict(test_data) %>%
    bind_cols(test_data) %>%
    metrics(truth = trait_value, estimate = .pred)
  
  # Get variable importance
  var_imp <- final_fit %>%
    extract_fit_parsnip() %>%
    vip::vi()
  
  # Cross-validation results
  cv_results <- rf_tuning %>%
    collect_metrics() %>%
    filter(.metric == "rmse") %>%
    filter(mtry == best_params$mtry, min_n == best_params$min_n)
  



```

